# Spark MLlib学习笔记

## reduceByKey和groupByKey区别

先上结论

> 在对大数据进行复杂计算时，reduceByKey优于groupByKey。
>
> 另外，如果仅仅是group处理，那么以下函数应该优先于 groupByKey ：
> 　　（1）、combineByKey 组合数据，但是组合之后的数据类型与输入时值的类型不一样。
> 　　（2）、foldByKey合并每一个 key 的所有值，在级联函数和“零值”中使用。





reduceByKey用于对每个key对应的多个value进行merge操作，最重要的是它能够在本地先进行merge操作，并且merge操作可以通过函数自定义。

groupByKey也是对每个key进行操作，但只生成一个sequence。需要特别注意“Note”中的话，它告诉我们：如果需要对sequence进行aggregation操作（注意，groupByKey本身不能自定义操作函数），那么，选择reduceByKey/aggregateByKey更好。这是因为groupByKey不能自定义函数，我们需要先用groupByKey生成RDD，然后才能对此RDD通过map进行自定义函数操作。



用法（结果一样，内部处理方式不同）

~~~scala
val words = Array("one", "two", "two", "three", "three", "three")  
  
val wordPairsRDD = sc.parallelize(words).map(word => (word, 1))  

val wordCountsWithReduce = wordPairsRDD.reduceByKey(_ + _)  
val wordCountsWithGroup = wordPairsRDD.groupByKey().map(t => (t._1, t._2.sum))  
~~~



当采用reduceByKeyt时，Spark可以在每个分区移动数据之前将待输出数据与一个共用的key结合。借助下图可以理解在reduceByKey里究竟发生了什么。 注意在数据对被搬移前同一机器上同样的key是怎样被组合的(reduceByKey中的lamdba函数)。然后lamdba函数在每个区上被再次调用来将所有值reduce成一个最终结果。整个过程如下：



![image-20201007171314279](https://raw.githubusercontent.com/j8130/picBed/master/img/image-20201007171314279.png)



当采用groupByKey时，由于它不接收函数，spark只能先将所有的键值对(key-value pair)都移动，这样的后果是集群节点之间的开销很大，导致传输延时。整个过程如下：

![image-20201007171355789](https://raw.githubusercontent.com/j8130/picBed/master/img/image-20201007171355789.png)







## RDD

RDD可以看成是一个简单的“数组”，对其进行操作只需要调用有限的数组中的方法即可。与一般数组的区别在于：RDD是分布式存储，可以更好地利用现有的云数据平台，并在内存中运行（省去大量与硬盘的IO）。本质是存储在不同节点计算机中的数据集



在Spark中，弹性指的是数据的存储方式，即数据在节点中进行存储的时候，既可以使用内存也可以使用硬盘；弹性还有一层意思是，RDD具有很强的容错性，具体指Spark在运行计算的过程中，不会因为某个节点错误而使得整个任务失败。不同节点并发运行的数据，如果在某一个节点发生错误时，RDD会自动将其在不同的节点中重试。



### RDD工作原理

RDD可以将其看成一个分布在不同节点中的分布式数据集，并将数据以数据块（Block）的形式存储在各个节点的计算机中，如下图所示



![image-20201007175229211](https://raw.githubusercontent.com/j8130/picBed/master/img/image-20201007175229211.png)



从上图可以看到，每个Block Master 管理着若干个BlockSlave，而每个BlockSlaver又管理着若干个BlockNode。当BlockSlave获得了每个Node节点的地址，又会反向BlockMaster注册每个Node的基本信息，形成分层管理。

而对于某个节点中存储的数据，如果使用频率较多，则BlockMaster会将其缓存在自己的内存中，这样如果以后需要调用这些数据，则可以直接从BlockMaster中读取。对于不再使用的数据，BlockMaster会向BlockSlave发送一组命令予以销毁。



> tip
>
> 窄依赖便于在单一节点上按次序执行任务，使任务可控。宽依赖更多的是考虑任务的交互和容错性。





## chapter04 MLlib 基本概念

RDD将存储数据转化成向量和矩阵的形式进行存储和计算，这样将数据定量化表示，能更准确地整理和分析结果



### MLlib 基本数据类型

MLlib支持较多的数据格式，从最基本的Spark数据集RDD到部署在集群中的向量和矩阵

MLlib基本数据类型

| 类型名称           | 释义                                                 |
| ------------------ | ---------------------------------------------------- |
| Local vector       | 本地向量集。主要向spark提供一组可进行操作的数据集和  |
| Labeled point      | 向量标签。让用户能够分类不同的数据集和               |
| Local matrix       | 本地矩阵。将数据集合以矩阵形式存储在本地计算机中     |
| Distributed matrix | 分布式矩阵。将数据集合以矩阵形式存储在分布式计算机中 |



 































































